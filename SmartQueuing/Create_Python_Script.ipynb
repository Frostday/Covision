{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting person_detect.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile person_detect.py\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "class Queue:\n",
    "    '''\n",
    "    Class for dealing with queues\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.queues=[]\n",
    "\n",
    "    def add_queue(self, points):\n",
    "        self.queues.append(points)\n",
    "\n",
    "    def get_queues(self, image):\n",
    "        for q in self.queues:\n",
    "            x_min, y_min, x_max, y_max=q\n",
    "            frame=image[y_min:y_max, x_min:x_max]\n",
    "            yield frame\n",
    "    \n",
    "#    def check_coords(self, coords):\n",
    " #       d={k+1:0 for k in range(len(self.queues))}\n",
    "  #      \n",
    "   #     for coord in coords:\n",
    "    #        for i, q in enumerate(self.queues):\n",
    "     #           if coord[0]>q[0] and coord[2]<q[2]:\n",
    "      #              d[i+1]+=1\n",
    "       # return d\n",
    "    \n",
    "    def check_coords(self, coords, initial_w, initial_h): \n",
    "        d={k+1:0 for k in range(len(self.queues))}\n",
    "        \n",
    "        dummy = ['0', '1' , '2', '3']\n",
    "        \n",
    "        for coord in coords:\n",
    "            xmin = int(coord[3] * initial_w)\n",
    "            ymin = int(coord[4] * initial_h)\n",
    "            xmax = int(coord[5] * initial_w)\n",
    "            ymax = int(coord[6] * initial_h)\n",
    "            \n",
    "            dummy[0] = xmin\n",
    "            dummy[1] = ymin\n",
    "            dummy[2] = xmax\n",
    "            dummy[3] = ymax\n",
    "            \n",
    "            for i, q in enumerate(self.queues):\n",
    "                if dummy[0]>q[0] and dummy[2]<q[2]:\n",
    "                    d[i+1]+=1\n",
    "        return d\n",
    "\n",
    "class PersonDetect:\n",
    "    '''\n",
    "    Class for the Person Detection Model.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model_name, device, threshold=0.60):\n",
    "        self.model_weights=model_name+'.bin'\n",
    "        self.model_structure=model_name+'.xml'\n",
    "        self.device=device\n",
    "        self.threshold=threshold\n",
    "\n",
    "        try:\n",
    "            self.model=IENetwork(self.model_structure, self.model_weights)\n",
    "            #self.model = core.read_network(self.model_structure, self.model_weights) # Does not work in this workspace!\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Could not Initialise the network. Have you enterred the correct model path?\")\n",
    "\n",
    "        self.input_name=next(iter(self.model.inputs))\n",
    "        self.input_shape=self.model.inputs[self.input_name].shape\n",
    "        self.output_name=next(iter(self.model.outputs))\n",
    "        self.output_shape=self.model.outputs[self.output_name].shape\n",
    "\n",
    "    def load_model(self):\n",
    "        \n",
    "        self.core = IECore()\n",
    "        self.exec_network = self.core.load_network(network=self.model, device_name=self.device, num_requests=1)\n",
    "        \n",
    "    def predict(self, image, initial_w, initial_h):\n",
    "        \n",
    "        input_img = image\n",
    "        # Pre-process the image\n",
    "        image = self.preprocess_input(image)\n",
    "        \n",
    "        # Perform async inference\n",
    "        infer_request_handle = self.async_inference(image)\n",
    "        \n",
    "        # Get output\n",
    "        res = self.get_output(infer_request_handle, 0, output=None)\n",
    "        \n",
    "        # Draw Bounding Box\n",
    "        image, coords, current_count = self.boundingbox(res, initial_w, initial_h, input_img)\n",
    "\n",
    "        return coords, image, current_count\n",
    "    \n",
    "    def preprocess_input(self, frame):\n",
    "        # Get the input shape\n",
    "        n, c, h, w = (self.core, self.input_shape)[1]\n",
    "        image = cv2.resize(frame, (w, h))\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = image.reshape((n, c, h, w))\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def async_inference(self, image):\n",
    "        infer_request_handle = self.exec_network.start_async(request_id=0, inputs={self.input_name: image})\n",
    "        while True:\n",
    "            status = self.exec_network.requests[0].wait(-1)\n",
    "            if status == 0:\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(1)\n",
    "        return infer_request_handle\n",
    "    \n",
    "    def get_output(self, infer_request_handle, request_id, output):\n",
    "        if output:\n",
    "            res = infer_request_handle.output[output]\n",
    "        else:\n",
    "            res = self.exec_network.requests[request_id].outputs[self.output_name]\n",
    "        return res    \n",
    "    \n",
    "    def boundingbox(self, res, initial_w, initial_h, frame):\n",
    "        current_count = 0\n",
    "        det = []\n",
    "        for obj in res[0][0]:\n",
    "            # Draw bounding box for object when it's probability is more than the specified threshold\n",
    "            if obj[2] > self.threshold:\n",
    "                xmin = int(obj[3] * initial_w)\n",
    "                ymin = int(obj[4] * initial_h)\n",
    "                xmax = int(obj[5] * initial_w)\n",
    "                ymax = int(obj[6] * initial_h)\n",
    "                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 55, 255), 1)\n",
    "                current_count = current_count + 1\n",
    "                det.append(obj)\n",
    "        return frame, det, current_count\n",
    "\n",
    "def main(args):\n",
    "    \n",
    "    model=args.model\n",
    "    device=args.device\n",
    "    video_file=args.video\n",
    "    max_people=args.max_people\n",
    "    threshold=args.threshold\n",
    "    output_path=args.output_path\n",
    "\n",
    "    start_model_load_time=time.time()\n",
    "    pd= PersonDetect(model, device, threshold)\n",
    "    pd.load_model()\n",
    "    total_model_load_time = time.time() - start_model_load_time\n",
    "\n",
    "    queue=Queue()\n",
    "    \n",
    "    try:\n",
    "        queue_param=np.load(args.queue_param)\n",
    "        for q in queue_param:\n",
    "            queue.add_queue(q)\n",
    "    except:\n",
    "        print(\"error loading queue param file\")\n",
    "\n",
    "    try:\n",
    "        cap=cv2.VideoCapture(video_file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Cannot locate video file: \"+ video_file)\n",
    "    except Exception as e:\n",
    "        print(\"Something else went wrong with the video file: \", e)\n",
    "    \n",
    "    initial_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    initial_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    out_video = cv2.VideoWriter(os.path.join(output_path, 'output_video.mp4'), cv2.VideoWriter_fourcc(*'avc1'), fps, (initial_w, initial_h), True)\n",
    "    \n",
    "    counter=0\n",
    "    start_inference_time=time.time()\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame=cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            counter+=1\n",
    "            \n",
    "            coords, image, current_count= pd.predict(frame, initial_w, initial_h)\n",
    "            \n",
    "            num_people = queue.check_coords(coords, initial_w, initial_h)\n",
    "            print(f\"Total People in frame = {len(coords)}\")\n",
    "            print(f\"Number of people in queue = {num_people}\")\n",
    "            \n",
    "            out_text=\"\"\n",
    "            y_pixel=25\n",
    "            \n",
    "            for k, v in num_people.items():\n",
    "                out_text += f\"No. of People in Queue {k} is {v} \"\n",
    "                if v >= int(max_people):\n",
    "                    out_text += f\" Queue full; Please move to next Queue \"\n",
    "                cv2.putText(image, out_text, (15, y_pixel), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "                out_text=\"\"\n",
    "                y_pixel+=40\n",
    "            out_video.write(image)\n",
    "            \n",
    "        total_time=time.time()-start_inference_time\n",
    "        total_inference_time=round(total_time, 1)\n",
    "        fps=counter/total_inference_time\n",
    "\n",
    "        with open(os.path.join(output_path, 'stats.txt'), 'w') as f:\n",
    "            f.write(str(total_inference_time)+'\\n')\n",
    "            f.write(str(fps)+'\\n')\n",
    "            f.write(str(total_model_load_time)+'\\n')\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    except Exception as e:\n",
    "        print(\"Could not run Inference: \", e)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument('--model', required=True)\n",
    "    parser.add_argument('--device', default='CPU')\n",
    "    parser.add_argument('--video', default=None)\n",
    "    parser.add_argument('--queue_param', default=None)\n",
    "    parser.add_argument('--output_path', default='/results')\n",
    "    parser.add_argument('--max_people', default=2)\n",
    "    parser.add_argument('--threshold', default=0.60)\n",
    "    \n",
    "    args=parser.parse_args()\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}